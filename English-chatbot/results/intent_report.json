{
  "deny": {
    "precision": 0.7307692307692307,
    "recall": 1.0,
    "f1-score": 0.8444444444444443,
    "support": 19,
    "confused_with": {}
  },
  "homebased_care_escalation": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 23,
    "confused_with": {
      "symptoms": 13,
      "prevention": 3,
      "statistics": 2
    }
  },
  "testing_centers": {
    "precision": 0.8275862068965517,
    "recall": 1.0,
    "f1-score": 0.9056603773584906,
    "support": 24,
    "confused_with": {}
  },
  "bot_challenge": {
    "precision": 0.6451612903225806,
    "recall": 1.0,
    "f1-score": 0.7843137254901961,
    "support": 20,
    "confused_with": {}
  },
  "homebased_care": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 10,
    "confused_with": {
      "prevention": 4,
      "testing_procedures": 3,
      "symptoms": 3
    }
  },
  "testing_procedures": {
    "precision": 0.85,
    "recall": 1.0,
    "f1-score": 0.9189189189189189,
    "support": 17,
    "confused_with": {}
  },
  "lockdown": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 19,
    "confused_with": {
      "fines_penalties": 19
    }
  },
  "vaccination_schedule": {
    "precision": 0.95,
    "recall": 1.0,
    "f1-score": 0.9743589743589743,
    "support": 19,
    "confused_with": {}
  },
  "chit_chat": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 18,
    "confused_with": {
      "testing_centers": 4,
      "statistics": 3,
      "fines_penalties": 3
    }
  },
  "testing_validity": {
    "precision": 0.9565217391304348,
    "recall": 1.0,
    "f1-score": 0.9777777777777777,
    "support": 22,
    "confused_with": {}
  },
  "statistics": {
    "precision": 0.8285714285714286,
    "recall": 1.0,
    "f1-score": 0.90625,
    "support": 29,
    "confused_with": {}
  },
  "thankyou": {
    "precision": 0.8235294117647058,
    "recall": 1.0,
    "f1-score": 0.9032258064516129,
    "support": 14,
    "confused_with": {}
  },
  "fines_penalties": {
    "precision": 0.8424657534246576,
    "recall": 1.0,
    "f1-score": 0.9144981412639406,
    "support": 123,
    "confused_with": {}
  },
  "prevention": {
    "precision": 0.7037037037037037,
    "recall": 1.0,
    "f1-score": 0.8260869565217391,
    "support": 19,
    "confused_with": {}
  },
  "sendoff": {
    "precision": 0.7619047619047619,
    "recall": 1.0,
    "f1-score": 0.8648648648648648,
    "support": 16,
    "confused_with": {}
  },
  "affirm": {
    "precision": 0.6774193548387096,
    "recall": 1.0,
    "f1-score": 0.8076923076923077,
    "support": 21,
    "confused_with": {}
  },
  "specify_location": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 31,
    "confused_with": {
      "affirm": 8,
      "salutation": 8,
      "deny": 6
    }
  },
  "symptoms": {
    "precision": 0.5675675675675675,
    "recall": 1.0,
    "f1-score": 0.7241379310344828,
    "support": 21,
    "confused_with": {}
  },
  "testing_costs": {
    "precision": 0.9565217391304348,
    "recall": 1.0,
    "f1-score": 0.9777777777777777,
    "support": 22,
    "confused_with": {}
  },
  "salutation": {
    "precision": 0.6551724137931034,
    "recall": 1.0,
    "f1-score": 0.7916666666666666,
    "support": 19,
    "confused_with": {}
  },
  "inappropriate": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 16,
    "confused_with": {
      "bot_challenge": 9,
      "thankyou": 3,
      "affirm": 2
    }
  },
  "vaccination_requirement": {
    "precision": 0.8260869565217391,
    "recall": 1.0,
    "f1-score": 0.9047619047619047,
    "support": 19,
    "confused_with": {}
  },
  "micro avg": {
    "precision": 0.7881040892193308,
    "recall": 0.7837338262476895,
    "f1-score": 0.7859128822984245,
    "support": 541
  },
  "macro avg": {
    "precision": 0.5728627981063459,
    "recall": 0.7272727272727273,
    "f1-score": 0.6375652988810954,
    "support": 541
  },
  "weighted avg": {
    "precision": 0.6289605129578446,
    "recall": 0.7837338262476895,
    "f1-score": 0.6949482124130502,
    "support": 541
  }
}